{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general purpose libraries\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from collections import OrderedDict\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/preetham7/Downloads/archive'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".csv\"):\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86666546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as ply_go\n",
    "import plotly.figure_factory as ply_ff\n",
    "import plotly.colors as ply_colors #.sequential.Oranges as orange_palette\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# DSP libraries\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display as librosa_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML and data modelling libraries\n",
    "from sklearn.preprocessing   import MinMaxScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,roc_curve, precision_recall_curve,confusion_matrix,precision_score, recall_score,average_precision_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43501a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/preetham7/Downloads/archive/'\n",
    "metadata_file = 'metadata_compiled.csv'\n",
    "metadata=pd.read_csv(data_dir+metadata_file,sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert strings 'True'/'False' to genuine booleans\n",
    "cols_to_boolean = (['respiratory_condition', 'fever_muscle_pain',\n",
    "                     'dyspnea_1', 'wheezing_1', 'stridor_1','choking_1', 'congestion_1', 'nothing_1',\n",
    "                     'dyspnea_2', 'wheezing_2', 'stridor_2','choking_2', 'congestion_2', 'nothing_2',\n",
    "                     'dyspnea_3', 'wheezing_3', 'stridor_3','choking_3', 'congestion_3', 'nothing_3',\n",
    "                     'dyspnea_4', 'wheezing_4', 'stridor_4','choking_4', 'congestion_4', 'nothing_4'])\n",
    "#metadata[cols_to_boolean] = metadata[cols_to_boolean].apply(lambda x: x.astype(bool))\n",
    "for c in cols_to_boolean:\n",
    "    metadata.loc[metadata[c].notnull(),c] = metadata.loc[metadata[c].notnull(),c].astype(bool) \n",
    "\n",
    "print(\"NULL or NA records for each column:\")\n",
    "print( metadata.isnull().sum() )\n",
    "    \n",
    "cols_to_fillna = ['gender', 'status','diagnosis_1','diagnosis_2','diagnosis_3','diagnosis_4']\n",
    "metadata[cols_to_fillna]=metadata[cols_to_fillna].fillna('n/a')\n",
    "\n",
    "#print(metadata.dtypes)\n",
    "#print(metadata.shape)\n",
    "metadata.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16575f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_title_layout = dict({\"text\":\"my distribution\", 'xanchor':'center', 'x':0.5, 'y':0.9, 'font':{'size':24}})\n",
    "my_xaxis_layout = dict(title=dict(text=\"my x axis\", font={'size':16}))\n",
    "my_layout = dict(title=my_title_layout,\n",
    "                xaxis= my_xaxis_layout)\n",
    "bin_size_dict = dict(cough_detected=0.001,SNR=0.5, age=1, gender=1, respiratory_condition=1, fever_muscle_pain=1, status=1 )\n",
    "xaxis_title_dict = dict(cough_detected=\"Cough Detection Score\",SNR=\"Signal-to-Noise Ratio\" , age=\"Age\", \n",
    "                        gender=\"Gender\", respiratory_condition=\"Resp. Condition\", fever_muscle_pain=\"Fever\", status=\"Status\" )\n",
    "\n",
    "for c in ['cough_detected','SNR', 'age', 'gender','respiratory_condition','fever_muscle_pain', 'status' ]:\n",
    "    hist_data = ply_go.Histogram(x=metadata[c], name=c, showlegend=False, xbins={'size':bin_size_dict[c]})\n",
    "    fig = ply_go.Figure(data=[hist_data], layout=my_layout)\n",
    "    fig.update_layout(title={'text': c+\" distribution\"}, xaxis={\"title\":{\"text\":xaxis_title_dict[c]}})\n",
    "    fig.show()\n",
    "###\n",
    "\n",
    "\n",
    "fig = ply_go.Figure( layout=my_layout)\n",
    "for tmp_diag in metadata['status'].unique():\n",
    "    violin_data = ply_go.Violin(x=metadata.loc[metadata['status']==tmp_diag, 'status'],\n",
    "                                y=metadata.loc[metadata['status']==tmp_diag, 'age'],\n",
    "                                name=tmp_diag,\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True)\n",
    "    fig.add_trace(violin_data)\n",
    "    #end for\n",
    "fig.update_layout(title={'text': \"Distribution of AGE by type of DIAGNOSYS\"}, xaxis={\"title\":{\"text\":None}}, \n",
    "                  yaxis={\"title\":{\"text\":\"AGE [years]\"}})\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = ply_go.Figure( layout=my_layout)\n",
    "for tmp_diag in metadata['status'].unique():\n",
    "    violin_data = ply_go.Violin(x=metadata.loc[metadata['status']==tmp_diag, 'status'],\n",
    "                                y=metadata.loc[metadata['status']==tmp_diag, 'cough_detected'],\n",
    "                                name=tmp_diag,\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True)\n",
    "    fig.add_trace(violin_data)\n",
    "    #end for loop on unique statuses\n",
    "\n",
    "    \n",
    "fig.update_layout(title={'text': \"Distribution of cough detection classifier by type of DIAGNOSYS\"}, \n",
    "                  xaxis={\"title\":{\"text\":None}}, \n",
    "                  yaxis={\"title\":{\"text\":\"Cough Detection Score\"}})\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = ply_go.Figure( layout=my_layout)\n",
    "for tmp_diag in metadata['status'].unique():\n",
    "    violin_data = ply_go.Violin(x=metadata.loc[(metadata['status']==tmp_diag)&(metadata['SNR']<100), 'status'],\n",
    "                                y=metadata.loc[(metadata['status']==tmp_diag)&(metadata['SNR']<100), 'SNR'],\n",
    "                                name=tmp_diag,\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True)\n",
    "    fig.add_trace(violin_data)\n",
    "    #end for loop on unique statuses\n",
    "\n",
    "    \n",
    "fig.update_layout(title={'text': \"Distribution of SNR by type of DIAGNOSYS\"}, \n",
    "                  xaxis={\"title\":{\"text\":None}}, \n",
    "                  yaxis={\"title\":{\"text\":\"Signal-to-Noise Ratio\"}})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_pivot_df(df, xcols, ycols, valcol):\n",
    "    summary_df = df[xcols+ycols+valcol]\n",
    "    summary_df.loc[summary_df[xcols[0]].isnull(),xcols] = 'n/a' #replace NA with a default string\n",
    "    summary_df.loc[summary_df[ycols[0]].isnull(),ycols] = 'n/a' #replace NA with a default string\n",
    "    summary_df = summary_df.groupby(xcols+ycols).count().reset_index()\n",
    "    print(summary_df)\n",
    "    pivot_df = pd.pivot_table(data=summary_df,values=valcol, index=xcols,columns=ycols)\n",
    "    pivot_df.columns = [ c[1] for c in pivot_df.columns ] # get rid of multiindex\n",
    "    return pivot_df\n",
    "\n",
    "def pandas_to_plotly_heatdata(df):\n",
    "    #print(df.index)\n",
    "    return {'x': df.columns.tolist(),\n",
    "            'y': df.index.tolist(),\n",
    "            'z': df.values.tolist()}\n",
    "\n",
    "# Heatmap Fever vs status\n",
    "meta_summary_df = summarise_pivot_df(metadata, ['fever_muscle_pain'], ['status'], ['uuid'])\n",
    "meta_summary_df = meta_summary_df[['healthy','symptomatic','COVID-19','n/a']]\n",
    "n = meta_summary_df.sum().sum()\n",
    "print(meta_summary_df.head(5) )\n",
    "\n",
    "heat_data = ply_go.Heatmap(pandas_to_plotly_heatdata(meta_summary_df), \n",
    "                           colorscale=ply_colors.sequential.Oranges,\n",
    "                           colorbar={'title':\"Entries\", 'titleside':\"top\"} ,\n",
    "                           text=meta_summary_df.values)\n",
    "rounded_annotation = [ [\"NA\" if pd.isnull(c) else \"{:.0f}\".format(c) for c in r] for r in heat_data['z']]\n",
    "fig = ply_ff.create_annotated_heatmap(z=heat_data['z'], \n",
    "                                      x=heat_data['x'],\n",
    "                                      y=[i for i,t in enumerate(heat_data['y'])],\n",
    "                                      annotation_text=rounded_annotation,\n",
    "                                      colorscale=heat_data['colorscale'],\n",
    "                                      showscale=True,\n",
    "                                      colorbar=heat_data['colorbar']  )\n",
    "fig.update_layout( yaxis={\"title\":{\"text\":\"Muscle Pain\"},\n",
    "                          \"tickmode\":'array',\"tickvals\":[2,1,0],\"ticktext\":['n/a','Yes','No']})\n",
    "fig.show()\n",
    "\n",
    "heat_data = ply_go.Heatmap(pandas_to_plotly_heatdata(100.0*meta_summary_df/n) ,\n",
    "                           colorscale=ply_colors.sequential.Oranges,\n",
    "                          colorbar={'title':\"Percentage\", 'titleside':\"top\"})\n",
    "rounded_annotation = [ [ \"NA\" if pd.isna(c)  else \"{:.2f}%\".format(c)  for c in r] for r in heat_data['z']]\n",
    "fig = ply_ff.create_annotated_heatmap(z=heat_data['z'], \n",
    "                                      x=heat_data['x'],\n",
    "                                      y=[i for i,t in enumerate(heat_data['y'])],\n",
    "                                      annotation_text=rounded_annotation,\n",
    "                                      colorscale=heat_data['colorscale'],\n",
    "                                      showscale=True,\n",
    "                                      colorbar=heat_data['colorbar'])\n",
    "fig.update_layout( yaxis={\"title\":{\"text\":\"Muscle Pain\"},\n",
    "                          \"tickmode\":'array',\"tickvals\":[2,1,0],\"ticktext\":['n/a','Yes','No']})\n",
    "fig.show()\n",
    "\n",
    "# Heatmap RespCond vs status\n",
    "meta_summary_df = summarise_pivot_df(metadata, ['respiratory_condition'], ['status'], ['uuid'])\n",
    "meta_summary_df = meta_summary_df[['healthy','symptomatic','COVID-19','n/a']]\n",
    "n = meta_summary_df.sum().sum()\n",
    "#print(meta_summary_df.head(5) )\n",
    "#print( pandas_to_plotly_heatdata(meta_summary_df) )\n",
    "heat_data = ply_go.Heatmap(pandas_to_plotly_heatdata(meta_summary_df), \n",
    "                           colorscale=ply_colors.sequential.Oranges,\n",
    "                           colorbar={'title':\"Entries\", 'titleside':\"top\"} ,\n",
    "                           text=meta_summary_df.values)\n",
    "rounded_annotation = [ [\"NA\" if pd.isnull(c) else \"{:.0f}\".format(c) for c in r] for r in heat_data['z']]\n",
    "fig = ply_ff.create_annotated_heatmap(z=heat_data['z'], \n",
    "                                      x=heat_data['x'],\n",
    "                                      #y=heat_data['y'],#\n",
    "                                      y=[int(i) for i,t in enumerate(heat_data['y']) ],\n",
    "                                      annotation_text=rounded_annotation,\n",
    "                                      colorscale=heat_data['colorscale'],\n",
    "                                      showscale=True,\n",
    "                                      colorbar=heat_data['colorbar']  )\n",
    "fig.update_layout( yaxis={\"title\":{\"text\":\"REspiratory Condition\"},\n",
    "                          \"tickmode\":'array',\"tickvals\":[2,1,0,],\"ticktext\":['n/a','Yes','No']})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b72a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*PySoundFile failed. Trying audioread instead*.', )\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display as librosa_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d23f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['audio_class'] = 'X' # default, we should have none by the end of this classification process\n",
    "metadata.loc[ (metadata['cough_detected'] >= 0.80) & (metadata['age']>=60) ,'audio_class'] = 'A'\n",
    "metadata.loc[ (metadata['cough_detected'] >= 0.80) & (metadata['age']>=40) & (metadata['age']<60) ,'audio_class'] = 'B'\n",
    "metadata.loc[ (metadata['cough_detected'] >= 0.80) & (metadata['age']< 40) ,'audio_class'] = 'C'\n",
    "metadata.loc[ (metadata['cough_detected'] < 0.80) & (metadata['age']>=60) ,'audio_class'] = 'D'\n",
    "metadata.loc[ (metadata['cough_detected'] < 0.80) & (metadata['age']>=40) & (metadata['age']<60) ,'audio_class'] = 'E'\n",
    "metadata.loc[ (metadata['cough_detected'] < 0.80) & (metadata['age']< 40) ,'audio_class'] = 'F'\n",
    "\n",
    "print(\"Entries subdivided in classes. Printing the number of entries for each class:\")\n",
    "print(metadata[['audio_class','uuid']].groupby(['audio_class']).count().rename(columns={'uuid':'N_entries'}) )\n",
    "\n",
    "print(\"\\n\\n\\nSplitting count by class and status:\")\n",
    "print(metadata[['audio_class','status','uuid']].groupby(['audio_class','status']).count().rename(columns={'uuid':'N_entries'}) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_audio(filename,indir, sr=None ):\n",
    "    print(filename,'  ',indir)\n",
    "    t, sr = librosa.load(indir+filename, sr=sr, mono=True)\n",
    "    print('import raw audio 3')\n",
    "    duration = t.shape[0]/sr #in seconds\n",
    "    mu_t = t.mean()\n",
    "    min_t = t.min()\n",
    "    max_t = t.max()\n",
    "    #tnorm = (t - mu_t )\n",
    "    #tnorm = tnorm / (max_t-mu_t)\n",
    "    f_token = np.array([filename[:-4]]).reshape(1, -1)\n",
    "    tokens = np.array([sr, duration, mu_t, max_t, min_t]).reshape(1,-1)\n",
    "    audio_df = pd.DataFrame(data= np.hstack((f_token, tokens)),\n",
    "                         columns=['AUDIO_FILE', 'SAMPLING_RATE','DURATION', 'MEAN_SIG', 'MAX_SIG', 'MIN_SIG' ],\n",
    "                         )\n",
    "    audio_df['SAMPLING_RATE'] = audio_df['SAMPLING_RATE'].astype(float).astype(int)#weird conversion from string to int \n",
    "    for i in ['DURATION', 'MEAN_SIG', 'MAX_SIG', 'MIN_SIG' ]:\n",
    "        audio_df[i] = audio_df[i].astype(float)\n",
    "    \n",
    "    return audio_df, t, sr\n",
    "    \n",
    "def zero_padding(t, sr, target_duration):\n",
    "    \"\"\"do zero-padding to get audio files all of the same duration; \n",
    "       this will allow us to have spectrograms all of the same size\"\"\"\n",
    "    target_len = target_duration * sr\n",
    "    if t.shape[0] > target_len:\n",
    "        t = t[0:target_len]\n",
    "    elif t.shape[0] < target_len:\n",
    "        n_pads = target_len - t.shape[0] \n",
    "        t = np.append(t, np.repeat(0,n_pads)  )\n",
    "    else:\n",
    "        pass\n",
    "    return t\n",
    "\n",
    "\n",
    "def calc_stft_power_spectrum(stft, sr, n_fft):\n",
    "    amplitudes = np.abs(stft)**2\n",
    "    frequencies = librosa.fft_frequencies(sr, n_fft)\n",
    "    psx = amplitudes.mean(axis=-1)\n",
    "    return frequencies, np.sqrt(psx)\n",
    "\n",
    "\n",
    "def calc_power_spectrum_welch(t, sr, n_fft):\n",
    "    f, psx = signal.welch(t, sr, window='hann',nfft=n_fft, noverlap=0,axis=-1, scaling='spectrum')\n",
    "    return f, np.sqrt(psx)\n",
    "\n",
    "def calc_spectral_features(t, sr, n_fft = 512, win_length = None, win_overlap=0.0, n_mfcc=None, rec_width=0):\n",
    "    \n",
    "    ### Calculate spectrograms:\n",
    "    ###   -) Short-time Fourier transform (STFT) for the power spectrum\n",
    "    ###   -) Mel-frequency cepstral coefficients (MFCC)\n",
    "    ###\n",
    "    ### win_overlap: float, [0.0, 1.0] ; if 0.0, windows will be NOT overlapping; 0.9999 means almost completely overlapping windows\n",
    "    ### rec_width: float, unused\n",
    "    ### \n",
    "    ### Output:\n",
    "    ###    stft: numpy.ndarray of dimension [n_fft/2, duration*my_sampling_rate/n_fft]; \n",
    "    ###          the n_fft/2 rows represent the frequencies of the Fast Fourier Transform in time domain;\n",
    "    ###          the columns are the time windows in which the raw signal has been subdivided for the FFT.\n",
    "    ###          The output values are complex numbers representing the amplitude of the sine and cosine\n",
    "    ###          at that specific frequency for that specific signal window\n",
    "    ###\n",
    "    ###   mfcc: numpy.array of dimensions [n_mfcc, duration*my_sampling_rate/n_fft];\n",
    "    ###         the n_mfcc rows indicate the different mel frequency bands;\n",
    "    ###         the columns are the time windows in which the raw signal has been subdivided for the FFT\n",
    "    ###         that is then mapped to the mel-frequncy bins.\n",
    "    ###\n",
    "    \n",
    "    if win_length is None:\n",
    "        win_length = n_fft\n",
    "    \n",
    "    if n_mfcc is None:\n",
    "        n_mfcc = n_fft\n",
    "    \n",
    "    assert (win_overlap>=0)&(win_overlap<1.0), \"Invalid value of win_overlap {} - it must be in range [0.0, 1.0) \".format(win_overlap)\n",
    "    hop_length = int(win_length*(1.0-win_overlap))\n",
    "    \n",
    "    #   stft_db = librosa.amplitude_to_db(  np.abs(librosa.stft(t, n_fft=n_fft, \n",
    "    #                                                              hop_length=hop_length, win_length=win_length )))\n",
    "    stft = librosa.stft(t, n_fft=n_fft, hop_length=hop_length, win_length=win_length ) \n",
    "    mfcc = librosa.feature.mfcc(t, sr=sr, n_mfcc=n_mfcc, dct_type=2)\n",
    "    #iirt_db = librosa.amplitude_to_db(  np.abs(librosa.iirt(t, hop_length=hop_length, win_length=win_length )) )\n",
    "\n",
    "    #R_stft = librosa.segment.recurrence_matrix(stft_db, mode='affinity', self=False, width=rec_width)\n",
    "    #R_iirt = librosa.segment.recurrence_matrix(iirt_db, mode='affinity', self=False, width=rec_width)\n",
    "\n",
    "    return stft,mfcc\n",
    "\n",
    "\n",
    "def stack_rows_with_pad(list_of_arrays):\n",
    "    f1 = lambda x: x.shape[1]\n",
    "    max_dim = max(list(map(f1,list_of_arrays)) )\n",
    "    #print(\"Original shapes:\")\n",
    "    #print([m.shape for m in list_of_arrays])\n",
    "    #print(\"Padding shapes:\")\n",
    "    #print([(m.shape[0], max_dim-m.shape[1] ) for m in list_of_arrays])\n",
    "    #print(\"nan pads:\")\n",
    "    #print([np.full([ m.shape[0],max_dim-m.shape[1] ],np.nan) for m in list_of_arrays])\n",
    "    padded_arrays = [ np.append(m, np.full([ m.shape[0],max_dim-m.shape[1] ],np.nan), axis=1 ) for m in list_of_arrays]\n",
    "    return np.concatenate(padded_arrays, axis=0)\n",
    "\n",
    "\n",
    "def calc_spectral_properties_welch(t, sr, n_fft, time_window_ms, freq_bins):\n",
    "    #######\n",
    "    ### Computes a whole bunch of spectral properties, after the reference (see section III.A)\n",
    "    ### https://myresearchspace.uws.ac.uk/ws/files/10993506/2018_12_15_Monge_Alvarez_et_al_Cough.pdf\n",
    "    ###\n",
    "    ### It splits the audio signal in smaller chunks. For each chunk computes the Power Spectrum Density\n",
    "    ### using the Welch method. It then averages the power for user-defined frequency bands.\n",
    "    ### At that point, we have many subsegments of the audio, k, and many average PSD, j\n",
    "    ### The spectral properties are calculated averaging and summing over k.\n",
    "    ### Output is a dictionary with various spectral properties, each one replicated j times \n",
    "    ### (as many as the frequency bands).\n",
    "    ###\n",
    "    \n",
    "    #sanity checks\n",
    "    assert len(freq_bins)>1,\"Error, input freq_bins must be a list with the boundaries of the frequency bins\"\n",
    "    \n",
    "    \n",
    "    #define how many ms is long each sample of the audio signal and how many values go in each subsegment\n",
    "    n_samples_tot = len(t)\n",
    "    if( time_window_ms is None ):\n",
    "        time_window_ms = 1000*n_samples_tot/sr\n",
    "    chunk_length = min(n_samples_tot, round(time_window_ms*sr/1000) )# how many audio samples fit in time_window_ms\n",
    "    n_chunks = int(np.ceil(n_samples_tot / chunk_length))\n",
    "    n_freq_bins = len(freq_bins)-1\n",
    "    out_all_freq = np.empty((n_freq_bins,0),float)\n",
    "    out_all_psx = np.empty((n_freq_bins,0),float)\n",
    "    #print(\"*\"*30+\"\\nLooping over {} chunks (tot t samples:{}, chunk l = {})\".format(n_chunks,n_samples_tot,chunk_length) )\n",
    "    for k in range(0,n_chunks,1):\n",
    "        tmin = k*chunk_length\n",
    "        tmax = min((k+1)*chunk_length, n_samples_tot)\n",
    "        tmp_segment = t[tmin:tmax]\n",
    "        freqs_welch, psx_welch = calc_power_spectrum_welch(tmp_segment,sr, n_fft)\n",
    "        #print(\"k={} n_freq_bins={} --> {} {}\".format(k,n_freq_bins,freqs_welch.shape, psx_welch.shape))\n",
    "        chunk_freq = np.empty((1,0),float)\n",
    "        chunk_psx = np.empty((1,0),float)\n",
    "    \n",
    "        for j in range(0, n_freq_bins,1):\n",
    "            freqmin = freq_bins[j]\n",
    "            freqmax = freq_bins[j+1]\n",
    "            freq_mask = (freqs_welch>=freqmin)&(freqs_welch<freqmax)\n",
    "            selfreqs = freqs_welch[freq_mask]\n",
    "            selpsx = psx_welch[freq_mask]\n",
    "            #print(\"{} {} |||  {} {} {}\".format(k,j,chunk_freq.shape,selfreqs.shape, selfreqs.reshape(1,-1).shape,selpsx.shape))\n",
    "            if(j==0):\n",
    "                chunk_freq = selfreqs.reshape(1,-1)\n",
    "                chunk_psx  = selpsx.reshape(1,-1)\n",
    "            else:\n",
    "                chunk_freq = stack_rows_with_pad([chunk_freq,selfreqs.reshape(1,-1)])  \n",
    "                chunk_psx = stack_rows_with_pad([chunk_psx,selpsx.reshape(1,-1)])  \n",
    "            #print( \"max chunk {} {} : {}\".format(k,j,np.nanmax(chunk_psx, axis=1) ) )\n",
    "        ### end for loop on j\n",
    "        \n",
    "        # append horizontally (row-wise) different frames\n",
    "        out_all_freq = np.append(out_all_freq,chunk_freq, axis=1)\n",
    "        out_all_psx = np.append(out_all_psx,chunk_psx, axis=1)\n",
    "    ####end for loop on k   \n",
    "    \n",
    "    #print(\"SHAPES:\")\n",
    "    #print(out_all_freq.shape)\n",
    "    #print(out_all_psx.shape)\n",
    "    \n",
    "    #Zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(t, frame_length=chunk_length, hop_length=chunk_length+1)\n",
    "    \n",
    "    # spectral centroid\n",
    "    psx_sum = np.nansum(out_all_psx, axis=1)\n",
    "    spec_centroid = (np.nansum(out_all_freq*out_all_psx, axis=1)/ psx_sum).reshape(-1,1)\n",
    "        \n",
    "    #spectral bandwidth\n",
    "    spec_bw = np.nansum( ((out_all_freq-spec_centroid)**2)*out_all_psx,axis=1)/psx_sum\n",
    "\n",
    "    #spectral crest factor\n",
    "    #C = 1.0 / (np.nanmax(out_all_freq) - np.nanmin(out_all_freq) +1)\n",
    "    #spec_crest = (np.nanmax(out_all_psx)/(C*psx_sum) ).reshape(-1,1)\n",
    "    psx_25 = np.nanquantile(out_all_psx,.25, axis=1)\n",
    "    psx_50 =np.nanquantile(out_all_psx,.50, axis=1)\n",
    "    psx_75 = np.nanquantile(out_all_psx,.75, axis=1)  \n",
    "    psx_max = np.nanmax(out_all_psx, axis=1)\n",
    "    #print(\"MAX: {} ; P25: {} ; P50: {} ; P75: {}\".format(psx_max, psx_25, psx_50, psx_75))\n",
    "    spec_crest = (psx_max-psx_50) / (psx_75 - psx_25)\n",
    "    \n",
    "    # spectral standard deviation\n",
    "    spec_sd = np.nanstd( out_all_psx,axis=1)\n",
    "    \n",
    "    #spectral skewness\n",
    "    n_entries = np.array([ len(row[~np.isnan(row)]) for row in out_all_psx])#.reshape(-1,)\n",
    "    skew_factors = [ e*np.sqrt(e-1)/(e-2) for e in n_entries]\n",
    "    spec_mean = np.nanmean(out_all_psx,axis=1).reshape(-1,1)\n",
    "    spec_skew = skew_factors*np.nansum((out_all_psx-spec_mean)**3, axis=1)  / spec_sd**3\n",
    "    \n",
    "    return zcr, spec_centroid.reshape(1,-1), spec_bw.reshape(1,-1), spec_crest.reshape(1,-1), spec_mean.reshape(1,-1),spec_sd.reshape(1,-1),spec_skew.reshape(1,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampling_rate = int(4096*2)  # Sampling rate, how frequently we want to take a value of the audio curve.\n",
    "                                 # the max frequency in the STFT will be (approximately) half of this\n",
    "                               \n",
    "my_n_fft = 512 # number of frequency bins to be calculated in the STFT; \n",
    "               # if my_window_size is None, this drives also the time-sampling window\n",
    "    \n",
    "my_n_mfcc = 26 # number of mel-frequencies used for the MFCC calculation. The original article used\n",
    "               # a number of 13 MFCC frequencies, I am trying to add some extra info   \n",
    "    \n",
    "my_window_size = None # should not be greater than n_fft\n",
    "target_duration = 10 # seconds; shorter audios will be zero padded; longer audios will be cut;\n",
    "                     # obtained from an earlier dry run over all data and charting the distribution \n",
    "                     # of duration of the raw sound samples; 10 sec corresponds to the 97th percentile and \n",
    "                     # represent a significant improvement in terms of computing time (x5 faster) \n",
    "                     # respect to more conservative choices like 70 seconds (99th percentile)\n",
    "\n",
    "\n",
    "iclass = \"A\"   # the class of audio records to be processesed (see previous cells)\n",
    "\n",
    "### these are the frequency bins used to compute short-term features as per the original article (used as inputs to the cough detection classifier).\n",
    "### Note that the code here will compute features for all bins but in the original paper they use only non-contiguous values.\n",
    "### For example, we keep the bin [0, 200] Hz but not the [200, 300] Hz; the lowest bin used inthe rest of htis analysis will be [0, 200] Hz,\n",
    "### the highest one will be [3800, 3900] Hz\n",
    "my_psd_freqs = [0.0, 200.0, 300.0, 425, 500.0, 650.0, 950.0, 1150.0, 1400.0, 1800.0, 2300.0, 2400.0, 2850.0, 2950.0, 3800.0, 3900, 4000]\n",
    "psd_feature_names =['SPEC_CENTROID', 'SPEC_WIDTH', 'SPEC_CREST', 'SPEC_MEAN', 'SPEC_SD', 'SPEC_SKEW']\n",
    "\n",
    "\n",
    "mfcc_feature_names = [ \"MFCC_MEAN_{:02}\".format(i) for i in range(0,my_n_mfcc,1)]\n",
    "mfcc_feature_names = mfcc_feature_names + [ \"MFCC_SD_{:02}\".format(i) for i in range(0,my_n_mfcc,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_data, audio_datadir, sr, target_duration, \n",
    "                 n_fft, n_mfcc, fft_window_size, psd_freq_bins,\n",
    "                 mfcc_feature_names, psd_feature_names, \n",
    "                 max_audio_samples=None, print_every_n=10):\n",
    "    ######################################################\n",
    "    ###\n",
    "    ### Prepares a dataframe with a collection of properties and sound features \n",
    "    ### that can be readily used later in a ML classification process\n",
    "    ### \n",
    "    ### input_data: pandas data.frame; an extract of the metadata file present in the original dataset\n",
    "    ###\n",
    "    ### audio_datadir: string; the path to the diretory where the audio files are stored\n",
    "    ###\n",
    "    ### sr: int; sampling rate\n",
    "    ###\n",
    "    ### target_duration: int; final length of audio sample, in seconds. All audio files will be formatted \n",
    "    ###                  to this duration; longer audios will be cut; shorter audios will be padded with zeros\n",
    "    ###\n",
    "    ### n_fft: int; number of frequency bins to be considered in the Fast Fourier Transform\n",
    "    ###\n",
    "    ### n_mfcc: int; number of Mel-freuqencies to be used when computing the MFCC\n",
    "    ###\n",
    "    ### max_audio_samples: int; maximum number of audio files to be processed. If None, all available UUIDs  \n",
    "    ###                    will be processed; otherwise, only the first max_audio_sample UUID will be considered\n",
    "    ###\n",
    "    ###\n",
    "    ### Output: The output of this loop is a big pandas dataframe with as many rows as audio files \n",
    "    ###         and as many columns as a series of audio features. \n",
    "    ###         The column list includes also the audio UUID and the sample label (the \"status\" column in the metadata file).\n",
    "    ###\n",
    "    ######################################################\n",
    "    \n",
    "    # get the full list of uuid to be processed\n",
    "    all_uuids = input_data['uuid'].values\n",
    "    if max_audio_samples is not None:\n",
    "        all_uuids[0:max_audio_samples]\n",
    "\n",
    "\n",
    "    # empty pandas df where to store all features for all UUIDs\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # init  timer and df containig some metadata of the audio files\n",
    "    skipped_uuids = []\n",
    "    audio_metadata = pd.DataFrame()\n",
    "    t_start = timer()\n",
    "\n",
    "\n",
    "    for idx, uuid in enumerate(all_uuids):\n",
    "              \n",
    "        tmp_audiofilename = uuid+\".webm\"\n",
    "        if not os.path.exists(audio_datadir+tmp_audiofilename):\n",
    "            # try to look for a .ogg file\n",
    "            tmp_audiofilename = uuid+\".ogg\"\n",
    "            if not os.path.exists(audio_datadir+tmp_audiofilename):\n",
    "                warn(\"WARNING! Could not find audio file for UUID: {}  . Skipping.\".format(uuid))\n",
    "                continue\n",
    "        print('1') \n",
    "        if idx % print_every_n ==0:\n",
    "            print(\"Processing file #{}: {}\".format(idx,tmp_audiofilename))\n",
    "\n",
    "        try:\n",
    "            tmp_df, tmp_audio, sr = import_raw_audio(tmp_audiofilename, indir=audio_datadir, sr=sr)\n",
    "        except FileNotFoundError as e_fnf:\n",
    "            print(\"Could not find audio file {}.\\n\\n\\n\".format(tmp_audiofilename))\n",
    "            skipped_uuids = skipped_uuids + [uuid]\n",
    "            continue #move to next file\n",
    "#         except Exception as e:\n",
    "#             print(\"Some other exception occurred\")\n",
    "#             raise e #rethrow exception\n",
    "\n",
    "        tmp_audio = zero_padding(tmp_audio, sr=sr, target_duration=target_duration) \n",
    "        tmp_df['UUID'] = uuid\n",
    "        audio_metadata = audio_metadata.append(tmp_df)\n",
    "\n",
    "\n",
    "        stft , mfcc = calc_spectral_features(tmp_audio, sr, n_fft=n_fft,n_mfcc=n_mfcc, win_length=fft_window_size, win_overlap=0.0)\n",
    "\n",
    "        ### extract mean and std dev for each mel-frequency in the mfcc\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_sd = np.std(mfcc,axis=1)\n",
    "        mfcc_features = np.append(mfcc_mean,mfcc_sd,axis=0)\n",
    "        mfcc_feat_dict = {name:val for name,val in zip(mfcc_feature_names,mfcc_features)}\n",
    "\n",
    "        ### Power Spectrum Density based short-term features\n",
    "        zcr,sc,sb,scf,ssmean, ssd, ssk = calc_spectral_properties_welch(tmp_audio,sr, my_n_fft,None, psd_freq_bins)\n",
    "        # consider only every second bin to reduce features; following original article freq bins\n",
    "        psd_features = np.array([ (x0, x1, x2, x3,x4,x5) for i, (x0, x1, x2, x3,x4,x5) in enumerate(zip(*sc, *sb,*scf,*ssmean, *ssd, *ssk)) if i%2==0]).transpose() \n",
    "\n",
    "        #now extract each element of the PSD feature (correspondignto a unique combination of spectral feature and freq bin)\n",
    "        n_freq_bins = psd_features.shape[1]\n",
    "        psd_features = psd_features.ravel()\n",
    "        psd_feature_names_expanded = [ [ \"{f}_{b:02}\".format(f=f,b=b) for b in range(0,n_freq_bins,1) ] for f in psd_feature_names]\n",
    "        psd_feature_names_expanded = list(chain.from_iterable(psd_feature_names_expanded))\n",
    "        assert len(zcr)==1, \"Zero-Crossing Rate vector has length different from 1: {}\".format(len(zcr))\n",
    "        assert len(psd_feature_names_expanded)==len(psd_features), \"Mismatch between number of spectral features ({nf}) and vector with their names ({nn})\".format(nf=len(psd_features) , nn=len(psd_feature_names_expanded)) \n",
    "        psd_feat_dict = { name:val for name,val in zip(psd_feature_names_expanded,psd_features)}\n",
    "        psd_feat_dict['ZCR'] = zcr[0,0]\n",
    "\n",
    "        # store all features in a pandas dataframe\n",
    "        tmp_df = input_data.loc[ tmp_metadata['uuid']==uuid, ['uuid','audio_class','cough_detected','SNR','age','gender','respiratory_condition','fever_muscle_pain','status'] ]\n",
    "        tmp_df.columns = [c.upper() for c in tmp_df.columns]\n",
    "        tmp_dict = tmp_df.to_dict(orient='records')\n",
    "        #assert len(tmp_dict)==1, \"ERROR! Multiple records for UUID {} : {}\".format(uuid,len(tmp_dict))\n",
    "        tmp_dict = OrderedDict(tmp_dict[0] ) \n",
    "        tmp_dict.update(mfcc_feat_dict)\n",
    "        tmp_dict.update( psd_feat_dict)\n",
    "        #tmp_df = pd.DataFrame(tmp_dict, columns=tmp_dict.keys())\n",
    "        all_data = all_data.append(pd.DataFrame(tmp_dict,index=[idx]))#, ignore_index=True)\n",
    "\n",
    "    ### end for loop over raw audio files\n",
    "    print(\"\\n{} files processed in {:.1f} seconds\\n\".format(idx+1, timer()-t_start ))\n",
    "    return all_data,audio_metadata\n",
    "####\n",
    "#### end prepare_data\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08976e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following looks more complicated than needed because I want first to keep all entries of the smallest group\n",
    "# then upsample the difference between that and the target number n_resampling. No pandas function is allowing me to do this.\n",
    "def sample_df_balanced(df, group_col, n, random=42):\n",
    "    assert isinstance(group_col,str), \"Input group_col must be a plain string with the column name: {}\".format(type(group_col))\n",
    "    #df_count = df[[group_col]].groupby([group_col]).cumcount()+1\n",
    "    df['N'] = np.zeros(len(df[group_col]))\n",
    "    df_count = df[[group_col,'N']].groupby([group_col]).count().reset_index() #cumcount()+1\n",
    "    \n",
    "    out_df = pd.DataFrame()\n",
    "    for igroup in df[group_col].unique():\n",
    "\n",
    "        n_orig = df_count.loc[df_count[group_col]==igroup,'N'].values[0]\n",
    "        if n_orig < n: # need to upsample\n",
    "            delta = max(n - n_orig, 0)\n",
    "            tmp_df = df.loc[df[group_col]==igroup, ]\n",
    "            delta_df = tmp_df.sample(n=delta,random_state=random,replace=False)\n",
    "            out_df = pd.concat([out_df,tmp_df,delta_df])\n",
    "        else: #downsample\n",
    "            tmp_df = df.loc[df[group_col]==igroup, ].sample(n=n,random_state=random,replace=False)\n",
    "            out_df = pd.concat([out_df,tmp_df])\n",
    "    ### end for loop over groups\n",
    "    return out_df.drop('N',axis=1,inplace=False)\n",
    "### end sample_df_balanced\n",
    "\n",
    "   \n",
    "# filter UUID, keeping only those in the desired class\n",
    "tmp_metadata = metadata.loc[metadata['audio_class']==iclass,]\n",
    "\n",
    "# remove entries where the SNR is low (hence the cough audio sound is of poor quality)\n",
    "# This cut should be optimised, at this stage I just decide to cut off the worst 10%\n",
    "tmp_metadata = tmp_metadata.loc[tmp_metadata['SNR']>=tmp_metadata['SNR'].quantile(0.10),]\n",
    "print(\"Before resampling, count of entries by STATUS class in the full data.frame:\")\n",
    "tmp_metadata_count = tmp_metadata[['uuid','status']].groupby(['status']).count()\n",
    "print(tmp_metadata_count)\n",
    "print(len(tmp_metadata.loc[tmp_metadata['status']=='COVID-19', 'uuid'].unique()))\n",
    "\n",
    "# every group will have a number of entries equal to the number of records \n",
    "# in the smallest group, rounded to the closest ten above\n",
    "n_resampling = int(np.ceil(tmp_metadata_count['uuid'].min()/10)*10)\n",
    "\n",
    "  \n",
    "    \n",
    "#tmp_metadata = tmp_metadata.groupby(['status']).sample(n=n_resampling,random_state=42,replace=False)\n",
    "tmp_metadata = sample_df_balanced(tmp_metadata, 'status', n_resampling) #tmp_metadata.groupby(['status']).sample(n=n_resampling,random_state=42,replace=False)\n",
    "print(\"\\nAfter resampling, count of entries by STATUS class in the full data.frame:\")\n",
    "print(tmp_metadata[['uuid','status']].groupby(['status']).count())\n",
    "print(len(tmp_metadata.loc[tmp_metadata['status']=='COVID-19', 'uuid'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6805ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data, all_audio_metadata = prepare_data(input_data=tmp_metadata, audio_datadir=data_dir, sr=my_sampling_rate, \n",
    "#                                             target_duration=target_duration, n_fft=my_n_fft, n_mfcc=my_n_mfcc, \n",
    "#                                             fft_window_size=my_window_size, psd_freq_bins=my_psd_freqs,\n",
    "#                                             mfcc_feature_names=mfcc_feature_names, psd_feature_names=psd_feature_names,\n",
    "#                                             max_audio_samples=None, print_every_n=20) \n",
    "\n",
    "# all_audio_metadata = all_audio_metadata.drop_duplicates(subset='UUID', keep='first') # this avoids spurious duplicates at the following merge\n",
    "\n",
    "# print(\"Merging dataframe with audio features and df with audio metadata\")\n",
    "# all_data = pd.merge(all_data,all_audio_metadata,on=['UUID'],how='inner')\n",
    "# all_data.drop(['AUDIO_FILE'],axis=1,inplace=True)\n",
    "\n",
    "# #print(all_data[['UUID','STATUS']].groupby(['STATUS']).count())\n",
    "# print(\"Shape of full dataframe with features and labels: {}\".format(all_data.shape))\n",
    "# all_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af31ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_data_filename = audio_outdir+\"/cough-classification-data_Class{}.pkl\".format(iclass )\n",
    "# pd.to_pickle(all_data, out_data_filename)  # save df to file\n",
    "# all_data.to_csv('coughvid_full.csv')\n",
    "#\n",
    "#all_data = pd.read_csv(data_dir_file+input_file,index_col=None,) # load df from file\n",
    "all_data = pd.read_csv('coughvid_full.csv')\n",
    "all_data = all_data.drop('Unnamed: 0',axis=1)\n",
    "### one more check that all covid status are balanced\n",
    "all_data[['UUID','STATUS']].groupby(['STATUS']).count().rename(columns={'UUID':'N_UUID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = all_data.copy()\n",
    "\n",
    "all_data = all_data.loc[ (all_data['COUGH_DETECTED'] >= 0.80) & (metadata['age']<70)] # ,'audio_class'] = 'A'\n",
    "metadata.loc[ (metadata['cough_detected'] >= 0.80) & (metadata['age']>=60) ,'audio_class'] = 'A'\n",
    "\n",
    "#print(metadata[['audio_class','status','uuid']].groupby(['audio_class','status']).count().rename(columns={'uuid':'N_entries'}) )\n",
    "all_data[['UUID','STATUS']].groupby(['STATUS']).count().rename(columns={'UUID':'N_UUID'})\n",
    "\n",
    "### Visualise sound and spectrograms for a given UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uuids = all_data['UUID'].unique()\n",
    "uuid_tmp = all_uuids[10] #\"0379c586-c500-483c-83a6-95b63afe6931\"#all_uuids[10]\n",
    "tmp_audiofilename = uuid_tmp+\".webm\"\n",
    "        \n",
    "tmp_df, tmp_audio, sr = import_raw_audio(tmp_audiofilename, indir=data_dir, sr=my_sampling_rate)\n",
    "tmp_audiofilename = uuid_tmp+\".webm\"\n",
    "tmp_audio = zero_padding(tmp_audio, sr=sr, target_duration=target_duration)                                                         \n",
    "stft , mfcc = calc_spectral_features(tmp_audio, sr, n_fft=my_n_fft,n_mfcc=my_n_mfcc,win_overlap=0.0)\n",
    "freqs_welch, psx_welch = calc_power_spectrum_welch(tmp_audio,sr, my_n_fft)\n",
    "        \n",
    "print(mfcc.shape)\n",
    "time_stamps = np.arange(0,target_duration, 1/my_sampling_rate)\n",
    "\n",
    "# plot raw signal\n",
    "line_data = ply_go.Scatter(x=time_stamps, \n",
    "                           y=tmp_audio,\n",
    "                           name=\"Audio signal\", showlegend=False)\n",
    "fig = ply_go.Figure(data=[line_data])#, layout=my_layout)\n",
    "fig.update_layout(title={'text': \"Raw audio (UUID:{})\".format(uuid_tmp)}, \n",
    "                  xaxis={\"title\":{\"text\":\"Time [s]\"}}, yaxis={\"title\":{\"text\":\"Amplitude\"}})\n",
    "fig.show()\n",
    "\n",
    "# plot STFT\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,18)) # tight_layout=False,constrained_layout=True\n",
    "fig.tight_layout()\n",
    "img0 = librosa.display.specshow(np.abs(stft), sr=sr, y_axis='log', x_axis='time', ax=ax)\n",
    "\n",
    "#img0 = librosa_display.specshow(x, y_axis='log', x_axis='time',\n",
    "#                               sr=my_sampling_rate, ax=ax)\n",
    "ax.set_title('Log-Frequency power spectrogram', size=18)\n",
    "fig.colorbar(img0, format=\"%+2.f\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# plot MFCC\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,18)) # tight_layout=False,constrained_layout=True\n",
    "fig.tight_layout()\n",
    "img0 = librosa.display.specshow(np.abs(mfcc), sr=sr, y_axis='log', x_axis='time', ax=ax)\n",
    "\n",
    "#img0 = librosa_display.specshow(x, y_axis='log', x_axis='time',\n",
    "#                               sr=my_sampling_rate, ax=ax)\n",
    "ax.set_title('MFCC spectrogram', size=18)\n",
    "fig.colorbar(img0, format=\"%+2.f\")\n",
    "fig.show()\n",
    "\n",
    "# plot power spectrum\n",
    "line_data = ply_go.Scatter(x=freqs_welch,#np.arange(0,target_duration,my_n_fft/(my_sampling_rate)), \n",
    "                           y=psx_welch,\n",
    "                           name=\"Power Spectrum density\", showlegend=False)\n",
    "fig = ply_go.Figure(data=[line_data])#, layout=my_layout)\n",
    "fig.update_layout(title={'text': \"Power Spectrum Density (UUID:{})\".format(uuid_tmp)}, \n",
    "                  xaxis={\"title\":{\"text\":\"Frequency [Hz]\"}}, yaxis={\"title\":{\"text\":\"Average Power\"}})\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = all_data.copy()\n",
    "all_uuids = sampled_data['UUID'].values\n",
    "\n",
    "#select X features to be used in ML classification\n",
    "#train_features = (['RESPIRATORY_CONDITION', 'FEVER_MUSCLE_PAIN','MEAN_SIG','MAX_SIG','MIN_SIG','ZCR']+\n",
    "#                  [ f for f in sampled_data.columns.values if f.startswith('MFCC_')] + \n",
    "#                  [ f for f in sampled_data.columns.values if f.startswith('SPEC_')])\n",
    "\n",
    "max_freq_features = 99\n",
    "train_features = (['RESPIRATORY_CONDITION', 'FEVER_MUSCLE_PAIN','MEAN_SIG','MAX_SIG','MIN_SIG','ZCR']+\n",
    "                  [f2 for f2 in [ f1 for f1 in sampled_data.columns.values  if f1.startswith('MFCC_')] if int(f2[-2:])<max_freq_features]+\n",
    "                  [f2 for f2 in [ f1 for f1 in sampled_data.columns.values  if f1.startswith('SPEC_')] if int(f2[-2:])<max_freq_features])\n",
    "\n",
    "y_label = 'STATUS'\n",
    "\n",
    "### this is used if one wants to reduce the number of classes/status; \n",
    "#sampled_data.loc[sampled_data['STATUS']=='symptomatic','STATUS'] = 'NOCOVID' \n",
    "#sampled_data.loc[sampled_data['STATUS']=='healthy','STATUS']     = 'NOCOVID' \n",
    "\n",
    "\n",
    "#print(train_features)\n",
    "print(\"Number of training X features: {}\".format(len(train_features)) )\n",
    "X_train, X_test, y_train, y_test, uuid_train, uuid_test = train_test_split(all_data[train_features].values, sampled_data[[y_label]].values, all_uuids,\n",
    "                                                                            test_size=0.2,random_state=612, stratify=sampled_data[y_label])\n",
    "print(\"Shapes of train X and y datasets: X->{}    y->{}\".format(X_train.shape ,y_train.shape))\n",
    "print(\"Shapes of test  X and y datasets: X->{}    y->{}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "print(\"\\n\\nTRAIN DATASET - Count of entries by STATUS:\\nhealthy={} \\tsymptomatic={} \\tcovid={}\\n\\n\".format(y_train[y_train==\"healthy\"].shape[0], y_train[y_train==\"symptomatic\"].shape[0], y_train[y_train==\"COVID-19\"].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "labenc = LabelEncoder()\n",
    "y_train_enc = labenc.fit_transform(y_train.ravel())\n",
    "y_enc_labels = labenc.classes_\n",
    "print(y_enc_labels)\n",
    "y_test_enc = labenc.transform(y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8483c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_df(ytrue, ypred):   \n",
    "    falseposrate, trueposrate, thresholds = metrics.roc_curve(ytrue, ypred)\n",
    "    roc_df = pd.DataFrame()\n",
    "    roc_df['FalsePosRate'] = falseposrate\n",
    "    roc_df['TruePosRate'] = trueposrate\n",
    "    roc_df['Thresholds'] = thresholds\n",
    "    return roc_df\n",
    "\n",
    "def prc_df(ytrue, ypred):   \n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(ytrue, ypred)\n",
    "    prc_df = pd.DataFrame()\n",
    "    prc_df['Precision'] = precision[:-1]\n",
    "    prc_df['Recall'] = recall[:-1]\n",
    "    prc_df['Thresholds'] = thresholds\n",
    "    return prc_df\n",
    "\n",
    "def plot_prc(recall, precision, ax,\n",
    "             prc_score=None, xrange=[-0.05,1.05],yrange=[-0.05,1.05]):\n",
    "    \n",
    "    if prc_score is not None:\n",
    "        prc_label='PRC Avg Score = {:.4}'.format(prc_score)\n",
    "    else:\n",
    "        prc_label=None\n",
    "    ax.plot(recall,precision,  'b', label=prc_label)\n",
    "    ax.plot([0,1],[1,0],'r--')\n",
    "    ax.set_title('Precision-Recall curve', fontsize=28)\n",
    "    ax.set_xlabel('Recall', fontsize=24)\n",
    "    ax.set_ylabel('Precision', fontsize=24)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax.set_xlim(xrange)\n",
    "    ax.set_ylim(yrange)\n",
    "    ax.legend(loc='lower left',fontsize=24)\n",
    "    ax.grid()\n",
    "    return ax      \n",
    "\n",
    "def score_eval(ytrue, ypreds, model_name=\"\", ylabels=None):\n",
    "    tmp_acc = accuracy_score(ytrue, ypreds)\n",
    "    tmp_precision = precision_score(ytrue, ypreds, average='macro')\n",
    "    tmp_recall = recall_score(ytrue, ypreds, average='macro')\n",
    "    tmp_cm = confusion_matrix(ytrue, ypreds)\n",
    "    print(\"{mn} accuracy / precision / recall: {a:.3f} / {p:.3f} / {r:.3f}\".format(a=tmp_acc, p=tmp_precision, r=tmp_recall, mn=model_name) )\n",
    "    print(\"\\n\\n\")\n",
    "    print(classification_report(ytrue, ypreds, target_names=ylabels) )\n",
    "    return tmp_acc,tmp_precision, tmp_recall, tmp_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599944e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP LOGISTIC REGRESSION (MULTICLASS)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_params = dict(multi_class='multinomial', penalty='l2', C=0.20, solver='newton-cg', random_state=991)\n",
    "\n",
    "logit_class = LogisticRegression(**logit_params)\n",
    "logit_model = logit_class.fit(X_train_norm, y_train_enc)\n",
    "logit_test  = logit_model.predict(X_test_norm )\n",
    "print(y_enc_labels)\n",
    "logit_acc, logit_precision, logit_recall, logit_cm = score_eval(y_test_enc, logit_test, \"Logit_multi\", ylabels=y_enc_labels)\n",
    "\n",
    "print(logit_cm)\n",
    "\n",
    "logit_coeffs = pd.concat([pd.DataFrame(train_features),pd.DataFrame(np.transpose(logit_model.coef_))], axis = 1,ignore_index=True)\n",
    "logit_coeffs.columns = np.append(['XVAR'], y_enc_labels,axis=0)\n",
    "logit_coeffs.sort_values('COVID-19')\n",
    "#logit_coeffs.sort_values('healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SETUP XGBOOST\n",
    "\n",
    "# cast train and test sample to a XGBoost DMatrix data container -- NOT NEEDED if using sklearn API !\n",
    "#dtrain = xgb.DMatrix(data=X_train_norm, label=y_train,feature_names=train_features)\n",
    "#dtest = xgb.DMatrix(data=X_test_norm, label=y_test,feature_names=train_features)\n",
    "\n",
    "#\n",
    "# define XGBoost classification model\n",
    "# xgb_params = {'max_depth': 3,   # max depth of a tree\n",
    "#               'n_estimators': 250,\n",
    "#               'learning_rate': 0.1,   # learning rate; smaller eta make convergence more accurate but slower\n",
    "#               'min_split_loss': 0.05, #gamma parameter in xgboost; the larger gamma, the more conservative the algo is in adding one extra leaf to the tree\n",
    "#               'reg_lambda':5.0,   # disable L2 reg only if features are all reasonably independent\n",
    "#               'reg_alpha':5.0,    #  L1 reg,tring to prune unnecessary features\n",
    "#               'objective': 'multi:softmax',\n",
    "#               'num_class': 3,     # number of classes to classify in the dataset\n",
    "#               'use_label_encoder':False,\n",
    "#               'subsample': 0.5,  #use only a fraction of the training set to grow the tree; if =1.0, subsampling is disabled\n",
    "#               #'colsample_bytree':0.50,\n",
    "#               'random_state':9443,\n",
    "#               'verbosity':0  #0: silent --> 3: very verbose\n",
    "#               }\n",
    "\n",
    "# define XGBoost classification model\n",
    "xgb_params = {'max_depth': 3,   # max depth of a tree\n",
    "              'n_estimators': 20,\n",
    "              'learning_rate': 0.2,   # learning rate; smaller eta make convergence more accurate but slower\n",
    "              #'min_split_loss': 0, #gamma parameter in xgboost; the larger gamma, the more conservative the algo is in adding one extra leaf to the tree\n",
    "              'reg_lambda':10.0,   # disable L2 reg only if features are all reasonably independent\n",
    "              'reg_alpha':0.0,    #  L1 reg,tring to prune unnecessary features\n",
    "              'objective': 'multi:softmax',\n",
    "              'num_class': 3,     # number of classes to classify in the dataset\n",
    "              'use_label_encoder':False,\n",
    "              'subsample': 1,  #use only a fraction of the training set to grow the tree; if =1.0, subsampling is disabled\n",
    "              #'colsample_bytree':0.50,\n",
    "              'random_state':9443,\n",
    "              'verbosity':0  #0: silent --> 3: very verbose\n",
    "              }\n",
    "\n",
    "#evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "xgb_class = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "# fit the model\n",
    "xgb_model = xgb_class.fit(X_train_norm, y_train_enc, \n",
    "                          eval_metric=['mlogloss'], \n",
    "                          eval_set=[(X_train_norm, y_train_enc), (X_test_norm, y_test_enc)],\n",
    "                          verbose=False)\n",
    "\n",
    "\n",
    "#%% run evaluation\n",
    "xgb_train = xgb_model.predict(X_train_norm )\n",
    "xgb_test = xgb_model.predict(X_test_norm )\n",
    "#xgb_test= labenc.inverse_transform(xgb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ad8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot global feature importance as calculated by xgboost\n",
    "xgb_importance = xgb_class.feature_importances_\n",
    "sorted_indices = np.flip(xgb_importance.argsort())\n",
    "xgb_importance = xgb_importance[sorted_indices]\n",
    "importance_labels = np.array(train_features)[sorted_indices]\n",
    "plt.barh(importance_labels[0:10], xgb_importance[0:10])\n",
    "\n",
    "\n",
    "### accuracy and valuation metrics calculated on the training sample\n",
    "xgb_acc, xgb_precision, xgb_recall , xgb_cm = score_eval(y_train_enc, xgb_train, \"XGBoost TRAIN\", ylabels=y_enc_labels)\n",
    "\n",
    "print(\"\\n\\nConfusion matrix - in-sample training dataset:\")\n",
    "print(xgb_cm)\n",
    "\n",
    "# Applying k-fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "n_folds = 5\n",
    "accuracies = cross_val_score(estimator = xgb_model, X = X_train, y = y_train_enc, cv = n_folds)\n",
    "print(\"\\n\\nEvaluating XGBoost model using training set and {}-fold cross validation: \\nAverage Accuracy {:.3f} +/- {:.3f}\".format(n_folds,accuracies.mean(), accuracies.std() ) )\n",
    "print(\"Fold accuracies: {}\\n\\n\".format(accuracies))\n",
    "\n",
    "\n",
    "### extract loss values for both training and test datasets asa function of iteration (i.e., estimator added to the BDT)\n",
    "xgb_train_results = xgb_model.evals_result()\n",
    "xgb_train_loss = xgb_train_results['validation_0']['mlogloss']\n",
    "xgb_test_loss  = xgb_train_results['validation_1']['mlogloss']\n",
    "iters = len(xgb_train_loss)\n",
    "x_iters = list(range(0, iters))\n",
    "\n",
    "line_data = [ply_go.Scatter(x=x_iters, \n",
    "                            y=xgb_train_loss,\n",
    "                            name=\"TRAIN\"),\n",
    "             ply_go.Scatter(x=x_iters, \n",
    "                            y=xgb_test_loss,\n",
    "                            name=\"TEST\")]\n",
    "fig = ply_go.Figure(data=line_data)#, layout=my_layout)\n",
    "fig.update_layout(title={'text': \"Evaluation Log-Loss of XGBoost classifier\"}, \n",
    "                  xaxis={\"title\":{\"text\":\"Iteration\"}}, yaxis={\"title\":{\"text\":\"Multiclass Log-Loss\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\\n\\nVALIDATION USING TEST SAMPLE:\")\n",
    "xgb_acc, xgb_precision, xgb_recall , xgb_cm = score_eval(y_test_enc, xgb_test, \"XGBoost\", ylabels=y_enc_labels)\n",
    "\n",
    "print(\"\\n\\nConfusion matrix:\")\n",
    "print(xgb_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d93fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc48d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((X_train_norm, y_train_enc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f63f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.one_hot(y_train_enc, depth=3)\n",
    "y_test_oh = tf.one_hot(y_test_enc,depth = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b15444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(106,)),\n",
    "    keras.layers.Dense(units=256, activation='relu'),\n",
    "    #keras.layers.Dense(units=192, activation='relu'),\n",
    "    #keras.layers.Dense(units=192, activation='relu'),\n",
    "    keras.layers.Dense(units=192, activation='relu'),\n",
    "\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ff2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_norm,ys, \n",
    "    epochs=10, \n",
    "    steps_per_epoch=500\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tfa.metrics.F1Score(num_classes=3, threshold=0.5)\n",
    "metric.update_state(y_test_oh,nn_test)\n",
    "result = metric.result()\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_dec = labenc.inverse_transform(logit_test)\n",
    "xgb_test_dec = labenc.inverse_transform(xgb_test)\n",
    "logit_data = pd.DataFrame({'UUID':uuid_test, 'LOGIT_STATUS':logit_test_dec})\n",
    "xgb_data = pd.DataFrame({'UUID':uuid_test, 'XGB_STATUS':xgb_test_dec})\n",
    "pred_data = pd.merge(sampled_data, logit_data,on='UUID', how='left')\n",
    "pred_data = pd.merge(pred_data, xgb_data,on='UUID', how='left')\n",
    "#pred_data[['UUID','STATUS','LOGIT_STATUS','XGB_STATUS']].head()\n",
    "pred_data.loc[(pred_data['STATUS']==pred_data['LOGIT_STATUS']) & (pred_data['STATUS']!=pred_data['XGB_STATUS']) &(~pd.isnull(pred_data['XGB_STATUS'])),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04730a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869fd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6aeeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0558d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408a780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
